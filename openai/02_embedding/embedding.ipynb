{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c34da00-112b-48e1-8a10-da588a19124a",
   "metadata": {},
   "source": [
    "# Embedding\n",
    "\n",
    "## Demo code to generate your first embedding\n",
    "A quick demo code to generate embedding based on data from amazon-fine-food-reviews\n",
    "\n",
    "Please ensure you have *.env* file in your HOME/Documents/src/openai/ folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bfa353-f495-4844-9321-112c82907733",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "import os\n",
    "\n",
    "env_path = os.getenv(\"HOME\") + \"/Documents/src/openai/.env\"\n",
    "load_dotenv(dotenv_path=env_path, verbose=True)\n",
    "\n",
    "os.environ[\"OPENAI_API_TYPE\"] = \"azure\"\n",
    "os.environ[\"OPENAI_API_VERSION\"] = \"2023-05-15\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://pvg-azure-openai-uk-south.openai.azure.com\"\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "  api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "  api_version=\"2023-05-15\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd137c1-18ba-4b5d-a7e2-43831ccd2261",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = \"data/fine_food_reviews_1k.csv\"\n",
    "df = pd.read_csv(input_data, index_col = 0)\n",
    "df = df[[\"Time\", \"ProductId\", \"UserId\", \"Score\", \"Summary\", \"Text\"]]\n",
    "df = df.dropna()\n",
    "df[\"combined\"] = (\n",
    "    \"Title: \" + df.Summary.str.strip() + \"; Content: \" + df.Text.str.strip()\n",
    ")\n",
    "\n",
    "embedding_encoding = \"cl100k_base\"\n",
    "max_tokens = 8000  \n",
    "\n",
    "top_n = 1000\n",
    "df = df.sort_values(\"Time\").tail(top_n * 2) \n",
    "df.drop(\"Time\", axis=1, inplace=True)\n",
    "encoding = tiktoken.get_encoding(embedding_encoding)\n",
    "\n",
    "df[\"n_tokens\"] = df.combined.apply(lambda x: len(encoding.encode(x)))\n",
    "\n",
    "df = df[df.n_tokens <= max_tokens].tail(top_n)\n",
    "\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1aba43-bbad-4140-9aaf-50f86810a3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00165445-c962-42ef-8b89-5d436c148941",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_text(text, model=\"text-embedding-3-small\"):\n",
    "    res = client.embeddings.create(input=text, model=model)\n",
    "    return res.data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3093e0c6-2e48-4c43-b6c5-89c90512174c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't run. instead, load the data from fine_food_reviews_with_embeddings_1k.csv\n",
    "\n",
    "#df[\"embedding\"] = df.combined.apply(embedding_text)\n",
    "\n",
    "#output_datapath = \"data/fine_food_reviews_with_embeddings_1k.csv\"\n",
    "\n",
    "#df.to_csv(output_datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2512fe8-e78a-49e6-8f6c-c7d5dca62a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_datapath = \"data/fine_food_reviews_with_embeddings_1k.csv\"\n",
    "\n",
    "df_embedded = pd.read_csv(embedding_datapath, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8923ffc9-f47a-4be0-99b2-29ba0af08e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_embedded['embedding'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e9c19c-0e3d-4127-b8f1-c2e5d08f3801",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "df_embedded['embedding_vec'] = df_embedded['embedding'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967850da-bb5a-41df-a8e8-50c432db1b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# 从 matplotlib 包中导入 pyplot 子库，并将其别名设置为 plt。\n",
    "# matplotlib 是一个 Python 的 2D 绘图库，pyplot 是其子库，提供了一种类似 MATLAB 的绘图框架。\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "# 从 sklearn.manifold 模块中导入 TSNE 类。\n",
    "# TSNE (t-Distributed Stochastic Neighbor Embedding) 是一种用于数据可视化的降维方法，尤其擅长处理高维数据的可视化。\n",
    "# 它可以将高维度的数据映射到 2D 或 3D 的空间中，以便我们可以直观地观察和理解数据的结构。\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297fd17f-dbc8-4113-93fa-f2a9181303b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = np.vstack(df_embedded['embedding_vec'].values)\n",
    "tsne = TSNE(n_components=2, perplexity=15, random_state=42, init='random', learning_rate=200)\n",
    "vis_dims = tsne.fit_transform(matrix)\n",
    "colors = [\"red\", \"darkorange\", \"gold\", \"turquoise\", \"darkgreen\"]\n",
    "# 从降维后的坐标中分别获取所有数据点的横坐标和纵坐标\n",
    "x = [x for x,y in vis_dims]\n",
    "y = [y for x,y in vis_dims]\n",
    "\n",
    "# 根据数据点的评分（减1是因为评分是从1开始的，而颜色索引是从0开始的）获取对应的颜色索引\n",
    "color_indices = df_embedded.Score.values - 1\n",
    "\n",
    "# 确保你的数据点和颜色索引的数量匹配\n",
    "assert len(vis_dims) == len(df_embedded.Score.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebcd724-acba-4493-a314-41fe2d9956ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个基于预定义颜色的颜色映射对象\n",
    "colormap = matplotlib.colors.ListedColormap(colors)\n",
    "# 使用 matplotlib 创建散点图，其中颜色由颜色映射对象和颜色索引共同决定，alpha 是点的透明度\n",
    "plt.scatter(x, y, c=color_indices, cmap=colormap, alpha=0.3)\n",
    "\n",
    "# 为图形添加标题\n",
    "plt.title(\"Amazon ratings visualized in language using t-SNE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ab34fc-9167-4776-93ae-c4b99236f800",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# 从 scikit-learn中导入 KMeans 类。KMeans 是一个实现 K-Means 聚类算法的类。\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# np.vstack 是一个将输入数据堆叠到一个数组的函数（在垂直方向）。\n",
    "# 这里它用于将所有的 ada_embedding 值堆叠成一个矩阵。\n",
    "# matrix = np.vstack(df.ada_embedding.values)\n",
    "\n",
    "# 定义要生成的聚类数。\n",
    "n_clusters = 4\n",
    "\n",
    "# 创建一个 KMeans 对象，用于进行 K-Means 聚类。\n",
    "# n_clusters 参数指定了要创建的聚类的数量；\n",
    "# init 参数指定了初始化方法（在这种情况下是 'k-means++'）；\n",
    "# random_state 参数为随机数生成器设定了种子值，用于生成初始聚类中心。\n",
    "# n_init=10 消除警告 'FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4'\n",
    "kmeans = KMeans(n_clusters = n_clusters, init='k-means++', random_state=42, n_init=10)\n",
    "\n",
    "# 使用 matrix（我们之前创建的矩阵）来训练 KMeans 模型。这将执行 K-Means 聚类算法。\n",
    "kmeans.fit(matrix)\n",
    "\n",
    "# kmeans.labels_ 属性包含每个输入数据点所属的聚类的索引。\n",
    "# 这里，我们创建一个新的 'Cluster' 列，在这个列中，每个数据点都被赋予其所属的聚类的标签。\n",
    "df_embedded['Cluster'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853db0c7-cd9f-4a68-9af2-14baefd90804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先为每个聚类定义一个颜色。\n",
    "colors = [\"red\", \"green\", \"blue\", \"purple\"]\n",
    "\n",
    "# 然后，你可以使用 t-SNE 来降维数据。这里，我们只考虑 'embedding_vec' 列。\n",
    "tsne_model = TSNE(n_components=2, random_state=42)\n",
    "vis_data = tsne_model.fit_transform(matrix)\n",
    "\n",
    "# 现在，你可以从降维后的数据中获取 x 和 y 坐标。\n",
    "x = vis_data[:, 0]\n",
    "y = vis_data[:, 1]\n",
    "\n",
    "# 'Cluster' 列中的值将被用作颜色索引。\n",
    "color_indices = df_embedded['Cluster'].values\n",
    "\n",
    "# 创建一个基于预定义颜色的颜色映射对象\n",
    "colormap = matplotlib.colors.ListedColormap(colors)\n",
    "\n",
    "# 使用 matplotlib 创建散点图，其中颜色由颜色映射对象和颜色索引共同决定\n",
    "plt.scatter(x, y, c=color_indices, cmap=colormap)\n",
    "\n",
    "# 为图形添加标题\n",
    "plt.title(\"Clustering visualized in 2D using t-SNE\")\n",
    "\n",
    "# 显示图形\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d37c30c-b9a6-46b0-a563-922d73d44117",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73138ce8-269d-42fa-b04e-d5bb7bab3544",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_reviews(df, product_description, n=3, pprint=True):\n",
    "    product_embedding = embedding_text(product_description)\n",
    "    \n",
    "    df[\"similarity\"] = df.embedding_vec.apply(lambda x: cosine_similarity(x, product_embedding))\n",
    "\n",
    "    results = (\n",
    "        df.sort_values(\"similarity\", ascending=False)\n",
    "        .head(n)\n",
    "        .combined.str.replace(\"Title: \", \"\")\n",
    "        .str.replace(\"; Content:\", \": \")\n",
    "    )\n",
    "    if pprint:\n",
    "        for r in results:\n",
    "            print(r[:200])\n",
    "            print()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b331a6-80dd-4186-811a-72756e55ac08",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = search_reviews(df_embedded, 'poor package')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141c6b7a-ad5e-4407-9d9c-0b3845f764ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
