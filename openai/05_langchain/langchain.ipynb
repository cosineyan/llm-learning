{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b191d2a2-9a30-448b-a432-1f60a2f83531",
   "metadata": {},
   "source": [
    "# LangChain\n",
    "\n",
    "## Demo code to use LangChain\n",
    "A quick demo code to use LangChain.\n",
    "\n",
    "Please ensure you have *.env* file in your HOME/Documents/src/openai/ folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c38f27-21e0-4619-8682-22681a8669cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from pprint import pprint\n",
    "import os\n",
    "\n",
    "env_path = os.getenv(\"HOME\") + \"/Documents/src/openai/.env\"\n",
    "load_dotenv(dotenv_path=env_path, verbose=True)\n",
    "\n",
    "os.environ[\"OPENAI_API_TYPE\"] = \"azure\"\n",
    "os.environ[\"OPENAI_API_VERSION\"] = \"2023-05-15\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://pvg-azure-openai-uk-south.openai.azure.com\"\n",
    "\n",
    "model = AzureChatOpenAI(deployment_name=\"gpt-35-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa860857-5095-44ce-84dc-413d94c6c2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    " \n",
    "model = AzureChatOpenAI(deployment_name=\"gpt-35-turbo\")\n",
    " \n",
    "messages = [\n",
    "    SystemMessage(content=\"你是中国古代的圣贤孔子。请以如下格式使用文言文回答问题 {'author': '','answer': ''}\"),\n",
    "    HumanMessage(content=\"我应该如何看待学习？\"),\n",
    "    AIMessage(content=\"{''author': '孔子',answer': '学而时习之，不亦说乎？'}\"),\n",
    "    HumanMessage(content=\"我应该如何过好这一生？\")\n",
    "]\n",
    "\n",
    "print(model.invoke(messages).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93a60e2-e495-40bc-9a8a-f996b8500890",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = PromptTemplate.from_template(\"给一段《{book}》里的名言\")\n",
    "print(template)\n",
    "\n",
    "print(model.invoke(template.format(book='论语')).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd13e1c1-0f87-410b-ac22-e63a76b8fb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.prompts.chat import SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessagePromptTemplate.from_template(\"你是中国古代的圣贤{person}。请以如下格式使用文言文回答问题 {{'author': '','answer': ''}}\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{query}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(template)\n",
    "\n",
    "prompt = template.format_messages(person=\"孔子\", query=\"我应该如何看待学习？\")\n",
    "print(model.invoke(prompt).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9545a54-726c-402f-841d-d4c5c6f86568",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "class Answer(BaseModel):\n",
    "    author: str = Field(..., description=\"Author\")\n",
    "    answer: str = Field(..., description=\"Answer\")\n",
    "\n",
    "    @validator(\"answer\")\n",
    "    def validate_answer(cls, field) -> str:\n",
    "        return field\n",
    "\n",
    "    @validator(\"author\")\n",
    "    def validate_answer(cls, field) -> str:\n",
    "        return field\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Answer)\n",
    "\n",
    "template = \"\"\"你是中国古代的圣贤{person}。请使用文言文回答问题。\n",
    "{format_instructions}\n",
    "用户输入:\n",
    "{query}\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"person\", \"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()} \n",
    ")\n",
    "\n",
    "print(parser.get_format_instructions())\n",
    "\n",
    "model_input = prompt.format_prompt(person=\"孔子\",query=\"我应该如何看待学习？\")\n",
    "model_output= model.invoke(model_input.to_messages())\n",
    "\n",
    "print(model_output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b151d7-56e4-4564-a4b7-2c3b1ad23bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model \n",
    "print(chain.invoke({\"person\":\"孟子\",\"query\":\"我应该如何看待学习？\"}).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af5cabb-171c-4daf-8a99-3267d150390d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import SemanticSimilarityExampleSelector\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai.embeddings import AzureOpenAIEmbeddings\n",
    "\n",
    "examples = [\n",
    "    {\"input\": \"2+3\", \"output\": \"5\"},\n",
    "    {\"input\": \"我应该如何看待学习？\", \"output\": \"学而时习之，不亦说乎？\"},\n",
    "    {\"input\": \"What did the cow say to the moon?\", \"output\": \"nothing at all\"},\n",
    "    {\n",
    "        \"input\": \"Write me a poem about the moon\",\n",
    "        \"output\": \"One for the moon, and one for me, who are we to talk about the moon?\",\n",
    "    },\n",
    "]\n",
    "\n",
    "to_vectorize = [\" \".join(example.values()) for example in examples]\n",
    "embeddings = AzureOpenAIEmbeddings()\n",
    "vectorstore = Chroma.from_texts(to_vectorize, embeddings, metadatas=examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0604fb3d-782f-4797-b817-d21a8f4e5d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_selector = SemanticSimilarityExampleSelector(\n",
    "    vectorstore=vectorstore,\n",
    "    k=1,\n",
    ")\n",
    "\n",
    "# The prompt template will load examples by passing the input do the `select_examples` method\n",
    "example_selector.select_examples({\"input\": \"我应该如何过好这一生？\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2669c1-7776-4a87-8444-0d4665fe7dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    FewShotChatMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    input_variables=[\"input\"],\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=ChatPromptTemplate.from_messages(\n",
    "        [(\"human\", \"{input}\"), (\"ai\", \"{output}\")]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c13f939-9092-4d9e-ad20-e5396f59f264",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(few_shot_prompt.format(input=\"我应该如何过好这一生？\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3672a2-e1c8-48d7-8941-a8367816c614",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant.\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "print(few_shot_prompt.format(input=\"我应该如何过好这一生？\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34d10c5-9072-46be-a126-7ab8dfccd6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = final_prompt | model\n",
    "\n",
    "chain.invoke({\"input\": \"我应该如何过好这一生？\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
