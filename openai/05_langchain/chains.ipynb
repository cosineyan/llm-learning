{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08743e84-8184-49ab-82b1-e04786b330ba",
   "metadata": {},
   "source": [
    "# LangChain\n",
    "\n",
    "## Demo code to use LangChain\n",
    "A quick demo code to use chains in LangChain.\n",
    "\n",
    "Please ensure you have *.env* file in your HOME/Documents/src/openai/ folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b8cecc-66e9-4800-bd2d-f9ee81766027",
   "metadata": {},
   "source": [
    "## Initialize the model first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376b37a6-80e4-479f-b155-c586779e590d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from pprint import pprint\n",
    "import os\n",
    "\n",
    "env_path = os.getenv(\"HOME\") + \"/Documents/src/openai/.env\"\n",
    "load_dotenv(dotenv_path=env_path, verbose=True)\n",
    "\n",
    "os.environ[\"OPENAI_API_TYPE\"] = \"azure\"\n",
    "os.environ[\"OPENAI_API_VERSION\"] = \"2023-05-15\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://pvg-azure-openai-uk-south.openai.azure.com\"\n",
    "\n",
    "model = AzureChatOpenAI(deployment_name=\"gpt-35-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62bd4fc-0e95-4c94-976c-3c32bdb1d193",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\"type\": \"function\", \n",
    "         \"function\": {\n",
    "            \"name\": \"joke\", \n",
    "            \"description\": \"Generate a joke\",\n",
    "            \"parameters\": {\n",
    "                \"type\":\"object\",\n",
    "                \"properties\": {\n",
    "                    \"setup\": {\n",
    "                        \"type\": \"string\", \n",
    "                        \"description\": \"the setup for the joke\"\n",
    "                    },\n",
    "                    \"punchline\": {\n",
    "                        \"type\": \"string\", \n",
    "                        \"description\": \"the punchline for the joke\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"setup\", \"punchline\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b96609-438d-4f15-ae36-df8582019c30",
   "metadata": {},
   "source": [
    "## Simple LCEL\n",
    "\n",
    "1. ChatOpenAI to invoke prompt directly\n",
    "2. Simplest LCEL\n",
    "3. Inject simple command into ChatOpenAI\n",
    "4. Simple LCEL with standard format: prompt | model | output_parser\n",
    "5. Inject tools call into ChatOpenAI\n",
    "6. Tools call with ToolsParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fe4a67-3182-4797-a175-c9089a36be78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.output_parsers.openai_tools import JsonOutputToolsParser\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template('tell me a joke about {topic}')\n",
    "\n",
    "response = model.invoke(prompt.format(topic='programmers'))\n",
    "print(\"1. Direct model output:\")\n",
    "pprint(response)\n",
    "print(\"\\n\")\n",
    "\n",
    "chain_origin = prompt | model\n",
    "response = chain_origin.invoke({'topic':'programmers'})\n",
    "print(\"2. Simple chain output:\")\n",
    "pprint(response)\n",
    "print(\"\\n\")\n",
    "\n",
    "chain_with_stop_bind = prompt | model.bind(stop=['?'])\n",
    "response = chain_with_stop_bind.invoke({'topic':'programmers'})\n",
    "print(\"3. Chain with stop bind output:\")\n",
    "pprint(response)\n",
    "print(\"\\n\")\n",
    "\n",
    "chain_with_parser = prompt | model | StrOutputParser()\n",
    "response = chain_with_parser.invoke({'topic':'programmers'})\n",
    "print(\"4. Chain with String Output Parser output:\")\n",
    "pprint(response)\n",
    "print(\"\\n\")\n",
    "\n",
    "chain_with_tools_bind = prompt | model.bind(tools=tools, tool_choice={'type': 'function', 'function': {'name': 'joke'}})\n",
    "response = chain_with_tools_bind.invoke({'topic':'programmers'}, config={})\n",
    "print(\"5. Chain with Tools Call output:\")\n",
    "pprint(response)\n",
    "print(\"\\n\")\n",
    "\n",
    "chain_with_tools_bind = prompt | model.bind(tools=tools) | JsonOutputToolsParser()\n",
    "response = chain_with_tools_bind.invoke({'topic':'programmers'}, config={})\n",
    "print(\"6. Chain with Tools Parser output:\")\n",
    "pprint(response)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e2a349-511b-4f52-9366-91f99c02332d",
   "metadata": {},
   "source": [
    "## Simple Chain\n",
    "\n",
    "1. Test 1st prompt\n",
    "2. Test 2nd prompt with hard code input\n",
    "3. Combine 2 prompts together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70d03f1-16fe-48a7-a1d4-85dfee95bc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "prompt1 = ChatPromptTemplate.from_template(\"what is the year {person} won the gold medal in Olmypics?\")\n",
    "prompt2 = ChatPromptTemplate.from_template(\"who's the chairman of China in the year of {year}? respond in {language}\")\n",
    "\n",
    "chain1 = prompt1 | model | StrOutputParser()\n",
    "chain2 = (\n",
    "    {\"year\": itemgetter(\"year\"), \"language\": itemgetter(\"language\")}\n",
    "     | prompt2 | model | StrOutputParser()\n",
    ")\n",
    "chain3 = (\n",
    "    {\"year\": chain1, \"language\": itemgetter(\"language\")}\n",
    "     | prompt2 | model | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"1. Chain1 output:\")\n",
    "response = chain1.invoke({\"person\": \"刘翔\"})\n",
    "pprint(response)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"2. Chain2 output:\")\n",
    "response = chain2.invoke({\"year\": 2004, \"language\": \"Chinese\"})\n",
    "pprint(response)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"3. Chain3 output:\")\n",
    "response = chain3.invoke({\"person\": \"刘翔\", \"language\": \"Chinese\"})\n",
    "pprint(response)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b603b5-631d-4090-a3a6-ab61bfc98802",
   "metadata": {},
   "source": [
    "## A More Complex Chain\n",
    "\n",
    "1. input: prompt; output: year\n",
    "2. input: year; output: USA president's name 1\n",
    "3. input: year; output: USA president's name 2\n",
    "4. input: USA president's name 1, USA president's name 2; output: who's popular"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a951e4ce-bf50-46ff-8968-112c6b39ef18",
   "metadata": {},
   "source": [
    "<img src=\"images/langchain-chains.jpg\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116e3cac-542e-4c86-9788-5aaedc462d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables.base import RunnableMap\n",
    "from langchain.callbacks.tracers import ConsoleCallbackHandler\n",
    "\n",
    "prompt1 = ChatPromptTemplate.from_template(\"what's year when 刘翔 won the Olympics gold medal\")\n",
    "prompt2 = ChatPromptTemplate.from_template(\"who's the president of USA 5 years before {year}\")\n",
    "prompt3 = ChatPromptTemplate.from_template(\"who's the president of USA 5 years after {year}\")\n",
    "prompt4 = ChatPromptTemplate.from_template(\"who's more popular in USA between {president1} or {president2}\")\n",
    "\n",
    "chain1 = prompt1 | model | StrOutputParser()\n",
    "chain2 = {\"year\":itemgetter(\"year\")} | {\n",
    "    \"president1\": prompt2 | model | StrOutputParser(),\n",
    "    \"president2\": prompt3 | model | StrOutputParser()\n",
    "} | prompt4 | model | StrOutputParser()\n",
    "chain3 = RunnableMap({\"year\":chain1}) | {\n",
    "    \"president1\": prompt2 | model | StrOutputParser(),\n",
    "    \"president2\": prompt3 | model | StrOutputParser()\n",
    "} | prompt4 | model | StrOutputParser()\n",
    "\n",
    "print(\"1. Chain1 output:\")\n",
    "response = chain1.invoke({})\n",
    "pprint(response)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"2. Chain2 output:\")\n",
    "response = chain2.invoke({\"year\": 2004}, config={'callbacks': [ConsoleCallbackHandler()]})\n",
    "pprint(response)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"3. Chain3 output:\")\n",
    "response = chain3.invoke({}, config={'callbacks': [ConsoleCallbackHandler()]})\n",
    "pprint(response)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09da6969-cb21-4f65-8a53-c4493e91140e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
