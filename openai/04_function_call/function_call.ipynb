{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e88e2620-f29c-43ce-83f8-505f5f22a9ff",
   "metadata": {},
   "source": [
    "# Function Call\n",
    "\n",
    "## Demo code to make function calls\n",
    "A quick demo code to make function calls. \n",
    "\n",
    "Please ensure you have *.env* file in your HOME/Documents/src/openai/ folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7147a54a-cb34-4cf2-80cf-03a126104e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pysqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdedf83-f586-482b-980c-1e29a4d08e82",
   "metadata": {},
   "source": [
    "## Initialize the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c92993f-7cd3-4e8b-8c93-9eff865cb997",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "env_path = os.getenv(\"HOME\") + \"/Documents/src/openai/.env\"\n",
    "load_dotenv(dotenv_path=env_path, verbose=True)\n",
    "\n",
    "os.environ[\"OPENAI_API_TYPE\"] = \"azure\"\n",
    "os.environ[\"OPENAI_API_VERSION\"] = \"2023-05-15\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://pvg-azure-openai-uk-south.openai.azure.com\"\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "  api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "  api_version=\"2023-05-15\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca208f4a-8a9b-4d94-ad29-71181ffc7933",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "df = pd.read_csv(\"data/employees.csv\")\n",
    "\n",
    "def get_colleague_info(colleague_name: str):\n",
    "    df1 = df[df.name == colleague_name.lower()]\n",
    "    if df1.empty:\n",
    "        return None\n",
    "    else:\n",
    "        colleague_info = {\n",
    "            \"name\": df1.name.loc[df1.index[0]],\n",
    "            \"role\": df1.role.loc[df1.index[0]]\n",
    "        }\n",
    "        return json.dumps(colleague_info)\n",
    "    \n",
    "\n",
    "amap_key = os.getenv(\"AMAP_KEY\")\n",
    "\n",
    "df2 = pd.read_csv(\"data/base.csv\")\n",
    "\n",
    "def get_weather_by_colleague(colleague_name: str):\n",
    "    df3 = df2[df2.name == colleague_name.lower()]\n",
    "    if df3.empty:\n",
    "        return None\n",
    "    else:\n",
    "        city_id = df3.city_id.loc[df3.index[0]]\n",
    "        \n",
    "    url = f\"https://restapi.amap.com/v3/weather/weatherInfo?key={amap_key}&city={city_id}\"\n",
    "    r = requests.get(url)\n",
    "    result = r.json()\n",
    "    if \"lives\" in result and result[\"lives\"]:\n",
    "        return result[\"lives\"][0][\"weather\"]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad8fdf5-c703-4187-9402-512f4302c847",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\"type\": \"function\", \n",
    "         \"function\": {\n",
    "            \"name\": \"get_colleague_info\", \n",
    "            \"description\": \"Get colleagues' information\",\n",
    "            \"parameters\": {\n",
    "                \"type\":\"object\",\n",
    "                \"properties\": {\n",
    "                    \"colleague_name\": {\n",
    "                        \"type\": \"string\", \n",
    "                        \"description\": \"the name of the colleague\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\"type\": \"function\", \n",
    "         \"function\": {\n",
    "            \"name\": \"get_weather_by_colleague\", \n",
    "            \"description\": \"Get weather by colleague's name\",\n",
    "            \"parameters\": {\n",
    "                \"type\":\"object\",\n",
    "                \"properties\": {\n",
    "                    \"colleague_name\": {\n",
    "                        \"type\": \"string\", \n",
    "                        \"description\": \"the name of the colleague\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bdfff4-83a9-4f20-ba1b-525b7450fb96",
   "metadata": {},
   "source": [
    "## Run a Single Function Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3abddc7-4b5f-4682-b3fc-721e0144065e",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are a helpful assistant.\"\n",
    "user_prompt = \"what's the role of my colleague Michael?\"\n",
    "messages = [{\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "           ]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-35-turbo\", \n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ],\n",
    "    tools=tools, \n",
    "    tool_choice = 'auto'\n",
    ")\n",
    "\n",
    "response_message = response.choices[0].message\n",
    "\n",
    "if response.choices[0].finish_reason == \"tool_calls\":\n",
    "    print(\"GPT asked us to call a function.\")\n",
    "\n",
    "    messages.append(response_message)\n",
    "\n",
    "    for tool_call in response.choices[0].message.tool_calls: \n",
    "        function_name = tool_call.function.name\n",
    "        params = json.loads(tool_call.function.arguments)\n",
    "    \n",
    "        function_response = get_colleague_info (\n",
    "            **params\n",
    "        )\n",
    "\n",
    "        messages.append({\"role\": \"tool\", \"tool_call_id\": tool_call.id, \"name\": function_name, \"content\": function_response})\n",
    "        \n",
    "    second_response = client.chat.completions.create(\n",
    "        model=\"gpt-35-turbo\", \n",
    "        messages = messages,\n",
    "    )\n",
    "        \n",
    "    print(second_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75271e19-aac7-425b-9a79-cd16023739a0",
   "metadata": {},
   "source": [
    "## Run Multiple Function Callings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d8eb97-672f-4c01-951e-8c54f01df30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are a helpful assistant.\"\n",
    "user_prompt = \"what's the role and weather of my colleague Michael, Hunter and Mark?\"\n",
    "messages = [{\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "           ]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-35-turbo\", \n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ],\n",
    "    tools=tools, \n",
    "    tool_choice = 'auto'\n",
    ")\n",
    "\n",
    "response_message = response.choices[0].message\n",
    "\n",
    "if response.choices[0].finish_reason == \"tool_calls\":\n",
    "    print(\"GPT asked us to call a function.\")\n",
    "\n",
    "    messages.append(response_message)\n",
    "\n",
    "    for tool_call in response.choices[0].message.tool_calls: \n",
    "        function_name = tool_call.function.name\n",
    "        params = json.loads(tool_call.function.arguments)\n",
    "\n",
    "        if function_name == \"get_colleague_info\":\n",
    "            function_response = get_colleague_info (\n",
    "                **params\n",
    "            )\n",
    "        else:\n",
    "            function_response = get_weather_by_colleague (\n",
    "                **params\n",
    "            )\n",
    "\n",
    "        messages.append({\"role\": \"tool\", \"tool_call_id\": tool_call.id, \"name\": function_name, \"content\": function_response})\n",
    "\n",
    "    second_response = client.chat.completions.create(\n",
    "        model=\"gpt-35-turbo\", \n",
    "        messages = messages,\n",
    "    )\n",
    "        \n",
    "    print(second_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a455ef-62c2-46fb-ae3e-09022a250c19",
   "metadata": {},
   "source": [
    "## Define LangChain Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cecda5-65ca-475b-b480-d0e77933538b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "from langchain.tools import BaseTool, StructuredTool, tool\n",
    "\n",
    "@tool\n",
    "def get_colleague_info_enh(colleague_name: str):\n",
    "\n",
    "    \"\"\"Get the information of a colleague.\n",
    "\n",
    "    Args:\n",
    "        colleague_name: name of the colleague\n",
    "    \"\"\"\n",
    "    \n",
    "    df1 = df[df.name == colleague_name.lower()]\n",
    "    if df1.empty:\n",
    "        return None\n",
    "    else:\n",
    "        colleague_info = {\n",
    "            \"name\": df1.name.loc[df1.index[0]],\n",
    "            \"role\": df1.role.loc[df1.index[0]]\n",
    "        }\n",
    "        return json.dumps(colleague_info)\n",
    "\n",
    "@tool\n",
    "def get_weather_by_colleague_enh(colleague_name: str):\n",
    "\n",
    "    \"\"\"Get the weather of a colleague.\n",
    "\n",
    "    Args:\n",
    "        colleague_name: name of the colleague\n",
    "    \"\"\"\n",
    "    \n",
    "    df3 = df2[df2.name == colleague_name.lower()]\n",
    "    if df3.empty:\n",
    "        return None\n",
    "    else:\n",
    "        city_id = df3.city_id.loc[df3.index[0]]\n",
    "        \n",
    "    url = f\"https://restapi.amap.com/v3/weather/weatherInfo?key={amap_key}&city={city_id}\"\n",
    "    r = requests.get(url)\n",
    "    result = r.json()\n",
    "    if \"lives\" in result and result[\"lives\"]:\n",
    "        return result[\"lives\"][0][\"weather\"]\n",
    "    return None\n",
    "\n",
    "print(json.dumps(convert_to_openai_tool(get_colleague_info_enh), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8085d8c-66da-4df6-b7c5-a796f0274abb",
   "metadata": {},
   "source": [
    "## Run LangChain Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65ff781-bd12-42c0-b0c9-a79b32b02479",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.agents import Tool, AgentExecutor, create_openai_tools_agent\n",
    "from langchain import hub\n",
    " \n",
    "model = AzureChatOpenAI(deployment_name=\"gpt-35-turbo\")\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name = \"get_colleague_info_enh\",\n",
    "        func = get_colleague_info_enh.run,\n",
    "        description = \"useful for colleague information extraction\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name = \"get_weather_by_colleague_enh\",\n",
    "        func = get_weather_by_colleague_enh.run,\n",
    "        description = \"useful for colleague weather extraction\"\n",
    "    )\n",
    "]\n",
    "\n",
    "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "agent = create_openai_tools_agent(model, tools, prompt)\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent, tools=tools, verbose=False, handle_parsing_errors=True\n",
    ")\n",
    "agent_executor.invoke({\"input\": \"what's the role and weather of my colleague Michael, Hunter and Jack?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5696f266-61e6-40c7-8d3d-2f9845ed68b6",
   "metadata": {},
   "source": [
    "## Query SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b74b628-d3d5-4e1d-a186-139096068062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sql_completion(messages, model=\"gpt-35-turbo\"):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "        tools=[{  # 摘自 OpenAI 官方示例 https://github.com/openai/openai-cookbook/blob/main/examples/How_to_call_functions_with_chat_models.ipynb\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"ask_database\",\n",
    "                \"description\": \"Use this function to answer user questions about business. \\\n",
    "                            Output should be a fully formed SQL query.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"query\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": f\"\"\"\n",
    "                            SQL query extracting info to answer the user's question.\n",
    "                            SQL should be written using this database schema:\n",
    "                            {database_schema_string}\n",
    "                            The query should be returned in plain text, not in JSON.\n",
    "                            The query should only contain grammars supported by SQLite.\n",
    "                            \"\"\",\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"query\"],\n",
    "                }\n",
    "            }\n",
    "        }],\n",
    "    )\n",
    "    return response.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2b93cb-4a2a-4854-8c66-505b2c8746e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "database_schema_string = \"\"\"\n",
    "CREATE TABLE orders (\n",
    "    id INT PRIMARY KEY NOT NULL, -- Key field, should not be null\n",
    "    customer_id INT NOT NULL, -- customer id field, should not be null either\n",
    "    product_id STR NOT NULL, -- product id field\n",
    "    price DECIMAL(10,2) NOT NULL, -- price of the order\n",
    "    status INT NOT NULL, -- status of the order. 0 means not yet paid，1 means paid，2 means already refunded\n",
    "    create_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP, -- creation date, by default it's right now\n",
    "    pay_time TIMESTAMP -- pay date, could be empty\n",
    ");\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c50bdc-b5cf-42fc-a388-5aeca3ea9dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(':memory:')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(database_schema_string)\n",
    "\n",
    "mock_data = [\n",
    "    (1, 1001, 'TAPESTRY_BAG_1', 50.00, 0, '2024-2-10 10:00:00', None),\n",
    "    (2, 1001, 'TAPESTRY_BAG_2', 75.50, 1, '2024-2-16 11:00:00', '2024-02-16 12:00:00'),\n",
    "    (3, 1002, 'ASICS_SHOE_1', 85.25, 1, '2024-2-17 12:30:00', '2024-02-17 13:00:00'),\n",
    "    (4, 1002, 'HANAHAUSE_COKE', 60.75, 1, '2024-2-20 14:00:00', '2024-02-20 15:00:00'),\n",
    "    (5, 1003, 'SMALL_POTATO', 5.00, 0, '2024-2-28 16:00:00', None)\n",
    "]\n",
    "\n",
    "for record in mock_data:\n",
    "    cursor.execute('''\n",
    "    INSERT INTO orders (id, customer_id, product_id, price, status, create_time, pay_time)\n",
    "    VALUES (?, ?, ?, ?, ?, ?, ?)\n",
    "    ''', record)\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7b8991-18cc-4546-a60d-5a8301de0878",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_database(query):\n",
    "    cursor.execute(query)\n",
    "    records = cursor.fetchall()\n",
    "    return records\n",
    "\n",
    "\n",
    "#prompt = \"which customer spent the most accumulately? How much did he or she spend in total?\"\n",
    "prompt = \"what's the total sales of each product?\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"please answer the question based on the order table\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "response = get_sql_completion(messages)\n",
    "if response.content is None:\n",
    "    response.content = \"\"\n",
    "messages.append(response)\n",
    "print(response)\n",
    "\n",
    "if response.tool_calls is not None:\n",
    "    tool_call = response.tool_calls[0]\n",
    "    if tool_call.function.name == \"ask_database\":\n",
    "        arguments = tool_call.function.arguments\n",
    "        args = json.loads(arguments)\n",
    "        print(args[\"query\"])\n",
    "        result = ask_database(args[\"query\"])\n",
    "        print(result)\n",
    "\n",
    "        messages.append({\n",
    "            \"tool_call_id\": tool_call.id,\n",
    "            \"role\": \"tool\",\n",
    "            \"name\": \"ask_database\",\n",
    "            \"content\": str(result)\n",
    "        })\n",
    "        response = get_sql_completion(messages)\n",
    "        print(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
