{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e88e2620-f29c-43ce-83f8-505f5f22a9ff",
   "metadata": {},
   "source": [
    "# Function Call\n",
    "\n",
    "## Demo code to make function calls\n",
    "A quick demo code to make function calls. \n",
    "\n",
    "Please ensure you have *.env* file in your HOME/Documents/src/openai/ folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c92993f-7cd3-4e8b-8c93-9eff865cb997",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "env_path = os.getenv(\"HOME\") + \"/Documents/src/openai/.env\"\n",
    "load_dotenv(dotenv_path=env_path, verbose=True)\n",
    "\n",
    "os.environ[\"OPENAI_API_TYPE\"] = \"azure\"\n",
    "os.environ[\"OPENAI_API_VERSION\"] = \"2023-05-15\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://pvg-azure-openai-uk-south.openai.azure.com\"\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "  api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "  api_version=\"2023-05-15\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca208f4a-8a9b-4d94-ad29-71181ffc7933",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/employees.csv\")\n",
    "\n",
    "def get_colleague_info(colleague_name: str):\n",
    "    df1 = df[df.name == colleague_name.lower()]\n",
    "    if df1.empty:\n",
    "        return None\n",
    "    else:\n",
    "        colleague_info = {\n",
    "            \"name\": df1.name.loc[df1.index[0]],\n",
    "            \"role\": df1.role.loc[df1.index[0]]\n",
    "        }\n",
    "        return json.dumps(colleague_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad8fdf5-c703-4187-9402-512f4302c847",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\"type\": \"function\", \n",
    "         \"function\": {\n",
    "            \"name\": \"get_colleague_info\", \n",
    "            \"description\": \"Get colleagues' infomration\",\n",
    "            \"parameters\": {\n",
    "                \"type\":\"object\",\n",
    "                \"properties\": {\n",
    "                    \"colleague_name\": {\n",
    "                        \"type\": \"string\", \n",
    "                        \"description\": \"the name of the colleague\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3abddc7-4b5f-4682-b3fc-721e0144065e",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are a helpful assistant.\"\n",
    "user_prompt = \"what's the role of my colleague Michael, Hunter and Jack?\"\n",
    "messages = [{\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "           ]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-35-turbo\", \n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ],\n",
    "    tools=tools, \n",
    "    tool_choice = 'auto'\n",
    ")\n",
    "\n",
    "response_message = response.choices[0].message\n",
    "\n",
    "if response.choices[0].finish_reason == \"tool_calls\":\n",
    "    print(\"GPT asked us to call a function.\")\n",
    "\n",
    "    messages.append(response_message)\n",
    "\n",
    "    for tool_call in response.choices[0].message.tool_calls: \n",
    "        function_name = tool_call.function.name\n",
    "        params = json.loads(tool_call.function.arguments)\n",
    "    \n",
    "        function_response = get_colleague_info (\n",
    "            **params\n",
    "        )\n",
    "\n",
    "        messages.append({\"role\": \"tool\", \"tool_call_id\": tool_call.id, \"name\": function_name, \"content\": function_response})\n",
    "        \n",
    "    second_response = client.chat.completions.create(\n",
    "        model=\"gpt-35-turbo\", \n",
    "        messages = messages,\n",
    "    )\n",
    "        \n",
    "    print(second_response.choices[0].message.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cecda5-65ca-475b-b480-d0e77933538b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "from langchain.tools import BaseTool, StructuredTool, tool\n",
    "\n",
    "@tool\n",
    "def get_colleague_info_enh(colleague_name: str):\n",
    "\n",
    "    \"\"\"Get the information of a colleague.\n",
    "\n",
    "    Args:\n",
    "        colleague_name: name of the colleague\n",
    "    \"\"\"\n",
    "    \n",
    "    df1 = df[df.name == colleague_name.lower()]\n",
    "    if df1.empty:\n",
    "        return None\n",
    "    else:\n",
    "        colleague_info = {\n",
    "            \"name\": df1.name.loc[df1.index[0]],\n",
    "            \"role\": df1.role.loc[df1.index[0]]\n",
    "        }\n",
    "        return json.dumps(colleague_info)\n",
    "\n",
    "print(json.dumps(convert_to_openai_tool(get_colleague_info_enh), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65ff781-bd12-42c0-b0c9-a79b32b02479",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.agents import Tool, AgentExecutor, create_openai_tools_agent\n",
    "from langchain import hub\n",
    " \n",
    "model = AzureChatOpenAI(deployment_name=\"gpt-35-turbo\")\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name = \"get_colleague_info_enh\",\n",
    "        func = get_colleague_info_enh.run,\n",
    "        description = \"useful for colleague information extraction\"\n",
    "    )\n",
    "]\n",
    "\n",
    "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "agent = create_openai_tools_agent(model, tools, prompt)\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent, tools=tools, verbose=False, handle_parsing_errors=True\n",
    ")\n",
    "agent_executor.invoke({\"input\": \"what's the role of my colleague Michael, Hunter and Jack?\"})\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
